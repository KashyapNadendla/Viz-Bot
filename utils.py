import json
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
import os

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# def analyze_data_with_llm(data, prompt_type="analysis"):
#     llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model="gpt-4o-mini")

#     if prompt_type == "analysis":
#         prompt_template = PromptTemplate(
#             input_variables=["data_sample"],
#             template="You are a data analyst. Based on the following dataset sample: {data_sample}."
#         )
#         data_sample = json.dumps(data.sample(5).to_dict())
#         variables = {"data_sample": data_sample}
#         chain = LLMChain(llm=llm, prompt=prompt_template)
#         return chain.run(variables)

def analyze_data_with_llm(data, prompt_type="analysis", last_response=None, question=None):
    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model="gpt-4o-mini")

    if prompt_type == "analysis":
        prompt_template = PromptTemplate(
            input_variables=["data_sample"],
            template="You are a data analyst. Based on the following dataset sample: {data_sample}."
        )
        data_sample = json.dumps(data.sample(5).to_dict())
        variables = {"data_sample": data_sample}
    elif prompt_type == "model_suggestions":
        prompt_template = PromptTemplate(
            input_variables=["data_sample"],
            template="Suggest models for this dataset based on the sample: {data_sample}."
        )
        data_sample = json.dumps(data.sample(5).to_dict())
        variables = {"data_sample": data_sample}
    elif prompt_type == "visualization_suggestions":
        prompt_template = PromptTemplate(
            input_variables=["data_sample"],
            template="Suggest visualizations for this dataset sample: {data_sample}."
        )
        data_sample = json.dumps(data.sample(5).to_dict())
        variables = {"data_sample": data_sample}
    elif prompt_type == "feature_engineering":
        prompt_template = PromptTemplate(
            input_variables=["data_sample"],
            template="Suggest feature engineering techniques for this dataset sample: {data_sample}."
        )
        data_sample = json.dumps(data.sample(5).to_dict())
        variables = {"data_sample": data_sample}
    elif prompt_type == "custom":
        # Use the last bot response as context if available
        prompt_template = PromptTemplate(
            input_variables=["data_sample", "last_response", "question"],
            template="Based on the previous response: {last_response}, answer this question: {question} with reference to the dataset sample {data_sample}."
        )
        data_sample = json.dumps(data.sample(5).to_dict())
        variables = {"data_sample": data_sample, "last_response": last_response, "question": question}
    
    # Run the chain and return the result
    chain = LLMChain(llm=llm, prompt=prompt_template)
    response = chain.run(variables)
    return response.strip()



def analyze_with_llm(data_sample, user_selections, model_results):
    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model="gpt-4o-mini")
    """
    Analyzes the selected data and model results with the LLM and returns insights and recommendations.
    
    Args:
        data_sample (str): JSON string of a sample of the dataset.
        user_selections (dict): Dictionary containing the user's selections for the analysis.
        model_results (dict): Dictionary containing the results of the model evaluation.

    Returns:
        str: Analysis and recommendations generated by the LLM.
    """
    template = """Provide insights and recommendations based on the following information:

    Dataset Sample: 
    {data_sample}

    User Selections:
    {user_selections}

    Model Results:
    {model_results}

    Based on this context, please include any interpretations, recommendations, and potential next steps for further analysis or improvement.
    """
    
    prompt = PromptTemplate(
        input_variables=["data_sample", "user_selections", "model_results"],
        template=template
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    response = chain.run({
        "data_sample": data_sample,
        "user_selections": user_selections,
        "model_results": model_results
    })
    return response


def get_visualization_suggestions(data):
    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-4o-mini")
    data_sample = data.head(5).to_json(orient='records')
    prompt_template = PromptTemplate(
        input_variables=["data_sample"],
        template="""
        You are a data visualization expert. Given the following data sample:

        {data_sample}

        Suggest three effective visualizations to help explore and understand the data. For each suggestion, specify:
        - The type of plot
        - The columns to use
        - The insights it may reveal
        """
    )
    variables = {"data_sample": data_sample}
    chain = LLMChain(llm=llm, prompt=prompt_template)
    response = chain.run(variables)
    return response.strip()